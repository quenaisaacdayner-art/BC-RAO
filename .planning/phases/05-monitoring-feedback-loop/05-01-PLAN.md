---
phase: 05-monitoring-feedback-loop
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - bc-rao-api/app/models/monitoring.py
  - bc-rao-api/app/services/monitoring_service.py
  - bc-rao-api/app/integrations/reddit_client.py
  - bc-rao-api/app/services/email_service.py
autonomous: true
user_setup:
  - service: resend
    why: "Transactional email for shadowban alerts"
    env_vars:
      - name: RESEND_API_KEY
        source: "Resend Dashboard -> API Keys -> Create API Key"
    dashboard_config:
      - task: "Verify sender domain or use onboarding domain"
        location: "Resend Dashboard -> Domains"
  - service: reddit
    why: "Reddit API for dual-check monitoring (auth + anonymous)"
    env_vars:
      - name: REDDIT_CLIENT_ID
        source: "Reddit Apps -> Create app -> client_id"
      - name: REDDIT_CLIENT_SECRET
        source: "Reddit Apps -> Create app -> secret"
    dashboard_config:
      - task: "Create a Reddit 'script' app at https://www.reddit.com/prefs/apps"
        location: "Reddit Preferences -> Apps"

must_haves:
  truths:
    - "Monitoring service can register a post URL and create shadow_table entry with ISC snapshot"
    - "Reddit dual-check client can determine if a post is active, removed, or shadowbanned"
    - "Email service can send formatted shadowban alert via Resend"
  artifacts:
    - path: "bc-rao-api/app/models/monitoring.py"
      provides: "Pydantic models for monitoring requests/responses"
      contains: "RegisterPostRequest"
    - path: "bc-rao-api/app/services/monitoring_service.py"
      provides: "Post registration, status updates, audit classification, dashboard stats"
      contains: "MonitoringService"
    - path: "bc-rao-api/app/integrations/reddit_client.py"
      provides: "Dual-check Reddit client with auth + anonymous sessions"
      contains: "RedditDualCheckClient"
    - path: "bc-rao-api/app/services/email_service.py"
      provides: "Resend-based email sending for alerts"
      contains: "send_shadowban_alert"
  key_links:
    - from: "bc-rao-api/app/services/monitoring_service.py"
      to: "supabase shadow_table"
      via: "supabase_client insert/update"
      pattern: "supabase.*shadow_table"
    - from: "bc-rao-api/app/integrations/reddit_client.py"
      to: "Reddit API"
      via: "httpx GET requests (auth + anon)"
      pattern: "httpx.*reddit\\.com"
    - from: "bc-rao-api/app/services/email_service.py"
      to: "Resend API"
      via: "resend.Emails.send"
      pattern: "resend\\.Emails\\.send"
---

<objective>
Build the backend monitoring foundation: Pydantic models for the monitoring domain, the core MonitoringService with post registration/status/audit logic, a Reddit dual-check client for shadowban detection, and an email service for sending alerts via Resend.

Purpose: These are the foundational building blocks that the monitoring API endpoints and background workers will consume. Without these, no monitoring task can register posts, check Reddit status, send alerts, or classify outcomes.

Output: Four new Python modules providing the complete backend service layer for Phase 5.
</objective>

<execution_context>
@C:\Users\quena\.claude/get-shit-done/workflows/execute-plan.md
@C:\Users\quena\.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/05-monitoring-feedback-loop/05-CONTEXT.md
@.planning/phases/05-monitoring-feedback-loop/05-RESEARCH.md

@bc-rao-api/app/config.py
@bc-rao-api/app/models/draft.py
@bc-rao-api/app/services/collection_service.py
@bc-rao-api/app/integrations/supabase_client.py
@bc-rao-api/app/analysis/pattern_extractor.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Pydantic models + monitoring service + Reddit URL validator</name>
  <files>
    bc-rao-api/app/models/monitoring.py
    bc-rao-api/app/services/monitoring_service.py
  </files>
  <action>
**models/monitoring.py** — Create Pydantic models for the monitoring domain:

- `RegisterPostRequest`: Fields `post_url: str` (required), `campaign_id: UUID` (required). No draft_id or account_status — system infers draft mapping automatically per user decision. Add URL format validation using regex pattern: `^https?://(?:www\.)?(?:old\.)?reddit\.com/r/([a-zA-Z0-9_]{3,21})/comments/([a-z0-9]{5,9})(?:/[^/]+)?/?$`
- `RegisterPostResponse`: Fields `id: UUID`, `post_url: str`, `subreddit: str`, `reddit_post_id: str`, `status: str`, `isc_at_post: float`, `check_interval_hours: int`, `next_check_at: datetime`, `created_at: datetime`
- `ShadowEntry`: Full shadow_table row model with all spec columns — `id`, `draft_id`, `campaign_id`, `user_id`, `post_url`, `subreddit`, `status_vida` (use Literal["Ativo", "Removido", "404", "Shadowbanned", "Auditado"]), `conversational_depth`, `isc_at_post`, `account_status`, `check_interval_hours`, `total_checks`, `last_check_status`, `last_check_at`, `audit_result` (Optional Literal["SocialSuccess", "Rejection", "Inertia"]), `audit_completed_at`, `submitted_at`, `audit_due_at`, `created_at`
- `MonitoringDashboardStats`: Fields `active_count: int`, `removed_count: int`, `shadowbanned_count: int`, `total_count: int`, `success_rate: float`, `recent_alerts: list[dict]`
- `CheckResult`: Fields `timestamp: datetime`, `auth_status: str` ("ok"/"fail"), `anon_status: str` ("ok"/"fail"), `detected_status: str`
- `PostAuditResult`: Fields `shadow_id: UUID`, `outcome: Literal["SocialSuccess", "Rejection", "Inertia"]`, `audited_at: datetime`
- Helper function `parse_reddit_url(url: str) -> dict | None` that extracts subreddit and post_id from validated URL. Return `{"subreddit": str, "post_id": str}` or None if invalid.

**services/monitoring_service.py** — Create MonitoringService class:

- `__init__`: Get supabase client via `get_supabase()` from existing integrations
- `register_post(user_id: str, campaign_id: str, post_url: str) -> RegisterPostResponse`:
  1. Validate URL format using `parse_reddit_url()` — raise ValueError if invalid
  2. Check if post already registered for this user (query shadow_table by post_url + user_id) — raise ValueError if duplicate
  3. Infer draft mapping: query `generated_drafts` for most recent approved/posted draft matching subreddit + user_id within 24 hours
  4. Get current ISC for campaign+subreddit from `community_profiles` table
  5. Determine check_interval: query user's `subscriptions.account_status` — if "New" use 1h, else 4h
  6. Insert into shadow_table with all fields, set `next_check_at = now + check_interval`, `audit_due_at = now + 7 days`
  7. Return RegisterPostResponse

- `get_monitored_posts(user_id: str, campaign_id: str, status: str | None = None) -> list[ShadowEntry]`:
  Query shadow_table filtered by user_id, campaign_id, and optional status_vida filter. Order by submitted_at desc.

- `get_shadow_entry(shadow_id: str, user_id: str) -> ShadowEntry`:
  Fetch single entry by id, verify user_id matches for tenant isolation.

- `get_dashboard_stats(user_id: str, campaign_id: str) -> MonitoringDashboardStats`:
  Aggregate counts by status_vida, compute success_rate = active_count / total_count * 100. Fetch recent alerts from email_alerts table (last 5).

- `update_post_status(shadow_id: str, new_status: str, check_result: dict | None = None)`:
  Update shadow_table status_vida, increment total_checks, set last_check_at, last_check_status. Append check_result to metadata if provided.

- `run_post_audit(shadow_id: str, upvotes: int = 0, comments: int = 0) -> str`:
  Classify outcome: if status is "Shadowbanned" or "Removido" -> "Rejection". If status "Ativo" and (upvotes >= 10 or comments >= 3) -> "SocialSuccess". Else -> "Inertia". Update shadow_table with audit_result and audit_completed_at. Return outcome string.

All database operations use the existing supabase_client pattern (supabase.table("shadow_table").select/insert/update).
  </action>
  <verify>
    python -c "from app.models.monitoring import RegisterPostRequest, ShadowEntry, MonitoringDashboardStats, parse_reddit_url; print(parse_reddit_url('https://www.reddit.com/r/startups/comments/abc123/my_post/')); print('Models OK')"
  </verify>
  <done>
    RegisterPostRequest validates Reddit URLs via regex. parse_reddit_url extracts subreddit + post_id. MonitoringService can register posts, query entries, compute dashboard stats, update status, and run audit classification. All Pydantic models type-safe with correct field types matching shadow_table spec schema.
  </done>
</task>

<task type="auto">
  <name>Task 2: Reddit dual-check client + email service</name>
  <files>
    bc-rao-api/app/integrations/reddit_client.py
    bc-rao-api/app/services/email_service.py
  </files>
  <action>
**integrations/reddit_client.py** — Create RedditDualCheckClient:

Do NOT use PRAW (adds heavy dependency). Use httpx for lightweight HTTP requests to Reddit's public JSON endpoints (append `.json` to any Reddit URL).

- `__init__(self)`: Load `REDDIT_CLIENT_ID` and `REDDIT_CLIENT_SECRET` from settings. Create two httpx.AsyncClient instances:
  1. `auth_client`: Authenticated — obtains OAuth token via client_credentials grant to `https://www.reddit.com/api/v1/access_token` with client_id/secret. Sets `Authorization: Bearer {token}` header. User-Agent: "BC-RAO/1.0 (monitoring)"
  2. `anon_client`: Anonymous — no auth, uses `https://www.reddit.com` with `.json` suffix. User-Agent different string to avoid correlation.

- `async def get_oauth_token(self) -> str`: POST to Reddit token endpoint with `grant_type=client_credentials`. Cache token for 3500 seconds (expires at 3600). Return access token.

- `async def dual_check_post(self, reddit_post_id: str) -> Literal["active", "removed", "shadowbanned"]`:
  1. Auth check: GET `https://oauth.reddit.com/api/info?id=t3_{reddit_post_id}` with Bearer token. Check if post data exists and `removed_by_category` is null. Set auth_ok = True if post visible.
  2. Anon check: GET `https://www.reddit.com/comments/{reddit_post_id}.json` (no auth). Set anon_ok = True if response 200 and post data exists with `[removed]` not in selftext.
  3. Return: both ok -> "active". auth ok + anon fail -> "shadowbanned". auth fail -> "removed". Both fail -> "removed".
  4. On any httpx error, raise exception (caller handles retry).

- `async def fetch_post_metrics(self, reddit_post_id: str) -> dict`: GET post via auth endpoint, return `{"upvotes": int, "comments": int}` for 7-day audit.

- Add rate limit awareness: use `asyncio.sleep(2)` between auth and anon check to avoid hitting Reddit rate limits. Log all checks for debugging.

**services/email_service.py** — Create email service using Resend:

- Import resend, set `resend.api_key` from `settings.RESEND_API_KEY`
- `send_shadowban_alert(user_email: str, user_name: str, post_title: str, subreddit: str, post_url: str, dashboard_url: str) -> dict`:
  Build HTML email with:
  - Subject: "URGENT: Shadowban detected in r/{subreddit}"
  - Body: Red alert header, post details, "What This Means" section, 4-step immediate actions (pause 48h, review patterns, check blacklist, don't delete post), CTA button to dashboard
  - From: settings.EMAIL_FROM
  - Send via `resend.Emails.send(params)`, return response dict

- `send_success_alert(user_email: str, user_name: str, post_title: str, subreddit: str) -> dict`:
  Congratulatory email for SocialSuccess audit result. Green theme, link to dashboard.

- `send_adjustment_alert(user_email: str, user_name: str, post_title: str, subreddit: str, suggestion: str) -> dict`:
  Strategy pivot suggestion for Inertia/Rejection audit results. Neutral tone, link to blacklist page.

- `record_alert(user_id: str, shadow_id: str, alert_type: str, subject: str, body_preview: str)`:
  Insert into email_alerts table via supabase_client. Used for rate-limiting (max 1 shadowban alert per 24h).

- `can_send_shadowban_alert(user_id: str) -> bool`:
  Query email_alerts for most recent emergency alert for this user. Return True if none in last 24 hours.

All email sends wrapped in try/except — log error but never crash monitoring pipeline if email fails. Add `RESEND_API_KEY` check: if empty, log warning and skip email (development mode).
  </action>
  <verify>
    python -c "from app.integrations.reddit_client import RedditDualCheckClient; from app.services.email_service import send_shadowban_alert, can_send_shadowban_alert; print('Imports OK')"
  </verify>
  <done>
    RedditDualCheckClient performs dual-check (auth + anon) via httpx against Reddit JSON endpoints, returns Literal status. Email service sends formatted HTML alerts via Resend with rate limiting (1 shadowban email per 24h) and graceful fallback when RESEND_API_KEY is empty. Alert records stored in email_alerts table.
  </done>
</task>

</tasks>

<verification>
1. All four new modules import without errors
2. parse_reddit_url correctly validates Reddit URLs and extracts subreddit + post_id
3. MonitoringService methods have correct type signatures matching shadow_table schema
4. RedditDualCheckClient has dual_check_post and fetch_post_metrics async methods
5. Email service has send functions with HTML templates and rate-limiting
6. No new external dependencies beyond httpx (already in project) and resend
</verification>

<success_criteria>
- models/monitoring.py exports RegisterPostRequest, ShadowEntry, MonitoringDashboardStats, parse_reddit_url
- services/monitoring_service.py exports MonitoringService with register_post, get_monitored_posts, get_dashboard_stats, update_post_status, run_post_audit
- integrations/reddit_client.py exports RedditDualCheckClient with dual_check_post and fetch_post_metrics
- services/email_service.py exports send_shadowban_alert, send_success_alert, can_send_shadowban_alert, record_alert
- All modules follow existing codebase patterns (Pydantic models, supabase_client, settings import)
</success_criteria>

<output>
After completion, create `.planning/phases/05-monitoring-feedback-loop/05-01-SUMMARY.md`
</output>
