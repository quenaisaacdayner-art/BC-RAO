---
status: testing
phase: 04.1-draft-generation-anti-ai-optimization
source: 04.1-01-SUMMARY.md, 04.1-02-SUMMARY.md, 04.1-03-SUMMARY.md
started: 2026-02-13T12:00:00Z
updated: 2026-02-13T12:05:00Z
---

## Current Test

number: 6
name: 12 AI-Tell Detection Patterns
expected: |
  blacklist_validator.py contains 12 AI_TELL_PATTERNS total — the original 6 plus 6 new ones: symmetrical-structure, tidy-ending, enumeration, hedge-affirm, generic-descriptor, and over-enthusiasm.
awaiting: user response

## Tests

### 1. Positive Humanization Rules Replace Negation Rules
expected: In prompt_builder.py, ANTI_AI_RULES with "NEVER" instructions are replaced by HUMANIZATION_RULES with positive DO instructions containing Good/Bad example pairs across 4 sections.
result: pass

### 2. Structural Template Randomization
expected: When generating a draft, the prompt includes a randomly selected structural template (from 12 options like climax-first, tangent-first, mid-rant, etc.). Each generation should get a different post shape. The template name is stored in generation_params JSONB metadata.
result: pass

### 3. Ending Style Randomization
expected: Each generated draft gets a randomly selected ending style (from 8 options like abrupt stop, specific question, trailing off, etc.) instead of a tidy conclusion. The ending style is stored in generation_params JSONB metadata.
result: pass

### 4. Prose Archetype Guidance
expected: In prompt_builder.py, the archetype guidance for Journey, ProblemSolution, and Feedback is written as flowing prose paragraphs — not bullet-point lists that the LLM could mirror in its output.
result: pass

### 5. Model Parameters for Creative Variance
expected: Generation uses temperature=0.85, frequency_penalty=0.3, and presence_penalty=0.2. These are configured in router.py's generate_draft config and passed through client.py to OpenRouter API.
result: pass

### 6. 12 AI-Tell Detection Patterns
expected: blacklist_validator.py contains 12 AI_TELL_PATTERNS total — the original 6 plus 6 new ones: symmetrical-structure, tidy-ending, enumeration, hedge-affirm, generic-descriptor, and over-enthusiasm. Each has regex patterns and severity classification.
result: [pending]

### 7. Blocking Regeneration Loop
expected: In generation_service.py, when AI patterns are detected in a generated draft, the system automatically retries up to 2 more times (3 total attempts) with escalating anti-pattern feedback. Attempt 1 gets "messy writing" instructions, attempt 2 gets "maximum humanization". After max retries, best-effort draft is accepted.
result: [pending]

### 8. Regeneration Metadata Tracking
expected: generation_params JSONB stores regeneration metadata: attempt count and final AI pattern count, so you can monitor how many drafts required retries.
result: [pending]

### 9. Imperfection Metrics in Style Extractor
expected: style_extractor.py extracts 4 imperfection metrics from community posts: fragment_ratio, parenthetical_frequency, self_correction_rate, and dash_interruption_rate. These quantify how "messy" the community's writing is.
result: [pending]

### 10. Opinion Landscape in Style Guide
expected: style_guide_generator.py prompts the LLM for opinion landscape data with 5 fields: loved_tools, hated_tools, controversial_takes, tribal_knowledge, and strong_biases — capturing what the community believes and argues about.
result: [pending]

### 11. Imperfection Profile in Style Guide
expected: style_guide_generator.py includes imperfection profile with 4 fields: typical_typos, grammar_looseness, self_correction_frequency, and digression_tolerance — modeling the community's writing imperfections for generation.
result: [pending]

### 12. Burstiness Scoring
expected: scorers.py has a calculate_burstiness_score() function using coefficient of variation (std/mean of sentence lengths). Human-like CV 0.5-0.8 scores high (6-10), AI-like CV 0.2-0.4 scores low (0-6). Burstiness is weighted at 0.15 in the overall post score formula.
result: [pending]

### 13. Tests Pass
expected: All generation-related tests pass — at minimum the 65 blacklist validator tests and 137+ total generation tests. Run: pytest bc-rao-api/tests/test_blacklist_validator.py bc-rao-api/tests/test_style_extractor.py bc-rao-api/tests/test_style_guide_generator.py
result: [pending]

## Summary

total: 13
passed: 5
issues: 0
pending: 8
skipped: 0

## Gaps

[none yet]
